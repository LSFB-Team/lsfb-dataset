{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Download the LSFB dataset\n",
    "\n",
    "Both LSFB datasets, e.g. `cont` and `isol`, can be downloaded through *HTTP/HTTPS*. The  `lsfb-dataset` package provide a `Downloader` class taking care of the download according to your needs.\n",
    "For example, the downloader can filter out the files that you don't need and can also resume the downloading where it stops.\n",
    "\n",
    "| Name of the dataset | ID   | Poses | Videos (GB) |\n",
    "|---------------------|------|-------|-------------|\n",
    "| LSFB ISOL           | isol | 10GB  | 25GB        |\n",
    "| LSFB CONT           | cont | 31GB  | **~400GB**  |\n",
    "\n",
    "As you can see in this table, the datasets can be heavy, especially the videos of the LSFB CONT dataset.\n",
    "\n",
    "**!!! READ THE EXAMPLES BEFORE LAUNCHING THE CODE !!!**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Download LSFB ISOL Landmarks\n",
    "\n",
    "By default, the downloader will fetch the landmarks of the entirety of the specified dataset. The only mandatory parameters are the dataset name and the destination folder where the files are going to be downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lsfb_dataset import Downloader\n",
    "\n",
    "downloader = Downloader(dataset='isol', destination=\"./destination/folder\")\n",
    "downloader.download()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Download LSFB CONT Landmarks and Videos\n",
    "\n",
    "Here's another example where we download the videos and the landmarks of the continuous sign language discussions in LSFB CONT dataset.\n",
    "We have to specify that we want to include the videos, otherwise it will only download the poses (landmarks).\n",
    "\n",
    "Be aware that the videos are heavy. For example, this code will download more than 400 videos and can use hundreds of GB!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from lsfb_dataset import Downloader\n",
    "\n",
    "downloader = Downloader(\n",
    "    dataset='cont',\n",
    "    destination=\"./destination/folder\",\n",
    "    include_cleaned_poses=True,\n",
    "    include_videos=True,\n",
    ")\n",
    "downloader.download()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading a subset of LSFB ISOL (OR CONT)\n",
    "\n",
    "By default, the full dataset is downloaded. To only download a subset of the dataset, you need to set the parameter `splits` with at least one string.\n",
    "We recommend you to first try the `mini_sample` split as it contains a minimal number of instances. Other splits are `fold_0` to `fold_4`, `train` and `test`.\n",
    "The default split is `all`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lsfb_dataset import Downloader\n",
    "\n",
    "downloader = Downloader(\n",
    "    dataset='isol',\n",
    "    destination=\"./destination/folder\",\n",
    "    splits=['mini_sample'],\n",
    ")\n",
    "downloader.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Overwrite existing files\n",
    "\n",
    "By default, the downloader skip the existing files.\n",
    "If you want to re-download the dataset, you can disable this behavior."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from lsfb_dataset import Downloader\n",
    "\n",
    "downloader = Downloader(\n",
    "    dataset='isol',\n",
    "    destination=\"./destination/folder\",\n",
    "    splits=['mini_sample'],\n",
    "    skip_existing_files=False,\n",
    ")\n",
    "downloader.download()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## A more complex example\n",
    "\n",
    "Here's a more complex example where we only download the instances:\n",
    "* Of the subsets `fold_0` and `fold_2`;\n",
    "* Only the instances of the signers `20 to 39`;\n",
    "* Only download the raw poses (without any interpolation of the missing landmarks nor smoothing);\n",
    "* Only includes the landmarks of the `pose` (body) and the hands;\n",
    "* Without skipping the existing files."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from lsfb_dataset import Downloader\n",
    "\n",
    "downloader = Downloader(\n",
    "    dataset='isol',\n",
    "    destination=\"./destination/folder\",\n",
    "    splits=['fold_0', 'fold_2'],\n",
    "    signers=list(range(20, 40)),\n",
    "    include_cleaned_poses=False,\n",
    "    include_raw_poses=True,\n",
    "    include_videos=False,\n",
    "    landmarks=['pose', 'left_hand', 'right_hand'],\n",
    "    skip_existing_files=False,\n",
    ")\n",
    "downloader.download()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('virtualenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "8045820782ca801c0994244fd52bfe41f113f17162e99a1e24bedf0c7a1f2548"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
